# ===============================================================================
# Tailored Care Solutions - PSW Voice Reporting System
# Environment Variables Configuration
# Last Updated: October 25, 2025
# ===============================================================================

# =============================================================================
# V0 API/SDK CONFIGURATION (AI Component Generation - For Programmatic Use)
# =============================================================================
# Get your API key from: https://v0.dev/chat/settings/keys
# Requires: Premium ($20/month) or Team plan
# This enables AI assistants to generate components programmatically via v0-sdk
V0_API_KEY=v1:team_JgA7advstEmfWsXOAA2e6isW:3kqQMuQ9SgB165IpT8Eo6O5E

# =============================================================================
# WHISPER CONFIGURATION (Speech-to-Text)
# =============================================================================
# Model options: small (461MB, 50x realtime), medium (1.5GB, 25x realtime), large-v3 (2.9GB, 12x realtime)
WHISPER_MODEL=small

# Device options: cpu, mps (Metal on Mac), cuda (NVIDIA GPU)
WHISPER_DEVICE=mps

# Language: en (English), fil (Filipino), es (Spanish), pt (Portuguese), hi (Hindi), bo (Tibetan)
WHISPER_LANGUAGE=en

# Path to Whisper models directory
WHISPER_PATH=/Volumes/AI/models/whisper

# =============================================================================
# OLLAMA CONFIGURATION (Conversational AI)
# =============================================================================
# Ollama host URL
OLLAMA_HOST=http://localhost:11434

# Path to Ollama models directory
OLLAMA_MODELS=/Volumes/AI/models/ollama

# Primary model (fast, 1.5s response) - Qwen3 14B
OLLAMA_PRIMARY_MODEL=qwen2.5:14b-instruct-q4_K_M

# Quality model (balanced, 2.5s response) - Qwen3 30B
OLLAMA_QUALITY_MODEL=qwen2.5:30b-instruct-q4_K_M

# Maximum quality model (slow, 8s response) - Qwen3 72B
OLLAMA_MAX_QUALITY_MODEL=qwen2.5:72b-instruct-q4_K_M

# =============================================================================
# XTTS CONFIGURATION (Text-to-Speech)
# =============================================================================
# XTTS model path
XTTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2

# Device: cpu, mps (Metal), cuda
XTTS_DEVICE=mps

# Sample rate in Hz (24000 recommended for quality)
XTTS_SAMPLE_RATE=24000

# Path to XTTS models directory
XTTS_PATH=/Volumes/AI/models/xtts

# =============================================================================
# EMBEDDINGS CONFIGURATION
# =============================================================================
# Embeddings model
EMBEDDINGS_MODEL=bge-m3

# Embedding dimension
EMBEDDINGS_DIMENSION=1024

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Use quality mode (Qwen3 30B) vs speed mode (Qwen3 14B)
# true = use 30B for all responses, false = use 14B for conversations, 30B for final reports
USE_QUALITY_MODE=false

# Maximum concurrent AI requests
CONCURRENT_REQUESTS=10

# Maximum audio length in seconds
MAX_AUDIO_LENGTH=300

# =============================================================================
# LOCAL AI SERVER (Optional - for cloud integration via Tailscale)
# =============================================================================
# Local AI server URL (Tailscale IP or localhost)
LOCAL_AI_SERVER_URL=http://localhost:3001

# Server authentication token (generate secure token)
LOCAL_AI_SERVER_TOKEN=your-secure-token-here

# =============================================================================
# CLOUD DATABASE (Supabase)
# =============================================================================
# Supabase project URL
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co

# Supabase anonymous key (public)
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Supabase service role key (private - server-side only)
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# =============================================================================
# FALLBACK APIs (Emergency Only - when local AI unavailable)
# =============================================================================
# OpenAI API key (only used if local AI fails)
OPENAI_API_KEY=sk-...

# =============================================================================
# SESSION & SECURITY
# =============================================================================
# NextAuth secret (generate with: openssl rand -base64 32)
NEXTAUTH_SECRET=your-nextauth-secret-here

# NextAuth URL (your application URL)
NEXTAUTH_URL=http://localhost:3000

# =============================================================================
# MONITORING & LOGGING
# =============================================================================
# Log level: debug, info, warn, error
LOG_LEVEL=info

# Enable performance monitoring
ENABLE_MONITORING=true

# Enable audit logging
ENABLE_AUDIT_LOG=true

# =============================================================================
# TAILSCALE VPN (Optional - for cloud-to-local AI communication)
# =============================================================================
# Tailscale authentication key
TAILSCALE_AUTH_KEY=tskey-...

# =============================================================================
# CACHE & TEMP FILES
# =============================================================================
# Cache directory for temporary audio/transcript files
CACHE_PATH=/Volumes/AI/cache

# Auto-cleanup cache after N hours
CACHE_CLEANUP_HOURS=24

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Enable local mode (use mock AI when APIs unavailable)
ENABLE_LOCAL_MODE=true

# Enable debug logging for AI models
AI_DEBUG=false

# =============================================================================
# NOTES
# =============================================================================
# 1. Copy this file to .env.local and update with your values
# 2. Never commit .env.local to version control
# 3. Restart dev server after changing environment variables
# 4. All paths should be absolute
# 5. Boolean values: true/false (lowercase)
# 6. Generate secure tokens: node -e "console.log(require('crypto').randomBytes(32).toString('base64'))"
# ===============================================================================
